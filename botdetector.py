#!/usr/bin/env python3

import configparser
import csv
import os
import shutil
import sys

from feature_extractors import FEATURE_EXTRACTORS
from util import train_crm114, config_loader

class BotDetector(object):

    def __init__(self):
        """ Initialize BotDetector """

        config = config_loader.ConfigLoader().load()

        training_dir = config["training"]["root"]
        if (not os.path.isdir(training_dir)):
            os.mkdir(training_dir)

        # dictionary of initialized feture extractors
        self.extractors = {}

    def initialize_feature_extractors(self, extractors):
        """ Initialize feature extractors if they have not been initialized yet

        Args:
            extractors: A list of feature extractors to be initialized
        """

        if (extractors == "all"):
            extractors = FEATURE_EXTRACTORS.keys()
        for extractor in extractors:
            if (not extractor in self.extractors):
                print("Initializing %s" % extractor)
                self.extractors[extractor] = FEATURE_EXTRACTORS[extractor]()

    def run_tests(self, user, tweets, tests = "all"):
        """ Run tests

        Tests are defined as methods of the BotDetector class and begin with
        the name "test_", followed by the test's name.

        Each test should take the user's JSON and an array of the user's tweets
        as arguments and return an integer or floating point.

        If a test does not return an integer or floating point, it is not
        added to the results dictionary.

        Args:
            user: A dictionary of the twitter user
            tweets: A list of tweet dictionaries
            tests: A list of tests to run, or "all" to run all of them

        Returns:
            A dictionary where the indices are the test names and the values
            are the results
        """

        results = {}

        if (tests == "all"):
            tests = FEATURE_EXTRACTORS.keys()

        self.initialize_feature_extractors(tests)

        for test_name in sorted(tests):
            assert test_name in FEATURE_EXTRACTORS, (
                   "Feature extractor %s is undefined" % test_name)

            print("Running %s" % test_name)
            result = self.extractors[test_name].run(user, tweets)
            if ((type(result) is int) or (type(result) is float)):
                results[test_name] = result
            else:
                print("Test %s returned invalid value: %s" % (
                    test_name, result
                ))

        return results

def sample_users(collection, n_users):
    """ Sample n unique users from a MongoDB collection of tweets

    Args:
        collection: A pymongo.collection.Collection object
        n_users: The number of users to sample

    Returns:
        A list of Twitter user dicts
    """

    return [
        doc["user"]
        for doc in collection.aggregate([
            {"$group": {
                "_id": "$user.id",
                "user": {"$first": "$user"}
            }},
            {"$sample": {"size": 3}}
        ])
    ]

def analyze_users(botdetector, users, output_csv_path, tests = "all"):
    """ Create feature vectors from the given users

    Args:
        botdetector: A BotDetector object
        users: A list of Twitter user dicts
        output_csv_path: The path that the feature vectors should be written to
        tests: A list of feature extractors to use, or "all" if all available
            feature extractors should be used
    """

    if (tests == "all"):
        tests = FEATURE_EXTRACTORS.keys()
    tests = sorted(tests)

    with open(output_csv_path, "w") as f:
        writer = csv.DictWriter(
            f, fieldnames = ["user_id", "username"] + tests
        )
        writer.writeheader()
        for user in users:
            user_id = user["id"]
            username = user["screen_name"]

            print("========== Running new test on user: @%s" % username)
            print("Querying tweets")
            tweets = list(collection.find({"user.id": user_id}))
            print("Collected %d tweets\n" % len(tweets))

            results = botdetector.run_tests(
                user = user,
                tweets = tweets,
                tests = tests
            )
            results.update({
                "user_id": user_id,
                "username": username
            })

            writer.writerow(results)

            print(results)
            print()

    print("Wrote feature vectors to %s" % output_csv_path)

def load_feature_vectors(csv_path, fields_to_remove = ["user_id", "username"]):
    """ Load feature vectors from a CSV generated by analyze_users

    Features that have been extracted during the feature extraction stage are
    extracted from the CSV column labels; when training a classifier, all that
    is needed is to make sure that both CSV files have the same columns

    Args:
        csv_path: The path to the csv file
        fields_to_remove: Extra fields in the CSV file that contain extra data
            and must be ignored. If no fields are to be removed, supply an
            empty list.

    Returns:
        A list of feature vectors with the features sorted by feature extractor
        names
    """

    feature_vectors = []

    with open(csv_path, "r") as f:
        reader = csv.DictReader(f)
        tests = sorted(set(reader.fieldnames) - set(fields_to_remove))

        for row in reader:
            row = {
                key: float(row[key])
                for key in tests
            }
            feature_vectors.append([row[test] for test in tests])

    return feature_vectors

def train_classifier(spam_csv, ham_csv, n_estimators = 10):
    """ Train a random forest classifier by reading CSVs of feature vectors
    generated by analyze_users

    Args:
        spam_csv: The path to the CSV containing spammer feature vectors
        ham_csv: The path to the CSV containing normal user feature vectors
        n_estimators: The number of trees in the random forest

    Returns:
        A trained sklearn.ensemble.RandomForestClassifier object
    """

    classifier = sklearn.ensemble.RandomForestClassifier(
        n_estimators = n_estimators
    )

    spam_feature_vectors = load_feature_vectors(spam_csv)
    ham_feature_vectors = load_feature_vectors(ham_csv)

    feature_vectors = spam_feature_vectors + ham_feature_vectors
    class_labels = (["spam"] * len(spam_feature_vectors)
                    + ["ham"] * len(ham_feature_vectors))

    classifier.fit(feature_vectors, class_labels)

    return classifier

if (__name__ == "__main__"):
    import pymongo

    collection = pymongo.MongoClient()["local"]["geotweets"]
    botdetector = BotDetector()

    tests = list(FEATURE_EXTRACTORS.keys())
    tests.remove("Invalid")

    analyze_users(
        botdetector,
        sample_users(collection, 3),
        "out.csv",
        tests = tests
    )
    #test_random_users(collection, botdetector, 3)
